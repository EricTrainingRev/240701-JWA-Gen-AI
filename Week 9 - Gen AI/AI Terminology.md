# Terminology Study Guide
- hallucination: generating text that is incorrect or unrelated to the user input
    - this is typically caused by inadequate training data
- fine tuning: using task-specific data to make a pre-trained model more efficient with the task associated with the new data
- Generative Pre-trained Transformer (GPT): a type of artificial intelligence model used for natural language processing
- Bidirectional Encoder Representations from Transformers (BERT): the current technology standard for natural language processing models designed by Google and introduced in 2018
- Prompt Engineering: the practice of creating, implementing, and refining standardized queries for AI models to receive the most efficient and accurate responses needed for your questions
- Prompt Conditioning: adding additional information, such as examples, to a prompt to engineer a better response from the AI

## AI Usage
- AI Limitations:
    - missing vulnerabilities
    - missing runtime issues
    - difficulty in understanding complex code
    - can be prone to integrating negative sterotypes and misinformation about marginalized and vulnerable groups
- considerations when using AI
    - transparency and explainability of AI system
    - mitigate AI biases and unfair outcomes
    - protecting privacy
- Task AI is good for
    - detecting style violations and formatting issues
- technique used by AI for code review
    - machine learning based pattern recognition
- challenge when searching code bases
    - potential for logical errors

# Final Note
[This](https://www.promptingguide.ai/) website has some great information about prompt engineering and some techniques that have shown promise in generating accurate responses for users. I recommend scanning through the techniques in particular.